# This is the main configuration file for the application.
# ~~~~~

### DEV CONFIGURATION - you should update this before deployment.

# Secret key
# ~~~~~
# The secret key is used to secure cryptographics functions.
# If you deploy your application to several instances be sure to use the same key!
play.http.secret.key="%APPLICATION_SECRET%"

akka.http.server.request-timeout = 120 seconds


# The application languages
# ~~~~~
application.langs="en"

# Router
# ~~~~~
# Define the Router object to use for this application.
# This router will be looked up first when the application is starting up,
# so make sure this is the entry point.
# Furthermore, it's assumed your route file is named properly.
# So for an application router like `my.application.Router`,
# you may need to define a router file `conf/my.application.routes`.
# Default to Routes in the root package (and conf/routes)
# application.router=my.application.Routes

play.filters {

  # Enabled filters are run automatically against Play.
  # CSRFFilter, AllowedHostFilters, and SecurityHeadersFilters are enabled by default.

  enabled += helpers.AllowCORSFilter
  hosts {
    allowed = [".elb.amazonaws.com","localhost:9000"]
  }

  # Disabled filters remove elements from the enabled list.
  disabled += play.filters.headers.SecurityHeadersFilter #temporarily disabled, pending testing in the frontend
  disabled += play.filters.hosts.AllowedHostsFilter #at present, enabling this breaks the tests
  disabled += play.filters.csrf.CSRFFilter #temporarily disabled until CSRF implemented in the frontend
}

# Database configuration
# ~~~~~
# You can declare as many datasources as you want.
# By convention, the default datasource is named `default`
#
play.modules.disabled += "play.api.db.DBModule" //needed to make Slick work

# Default database configuration

// can now set DATABASE_URL to a JDBC URI to access database with this
slick.dbs.test.profile="slick.jdbc.PostgresProfile$"

slick.dbs.test.db.url="jdbc:postgresql://localhost:5432/projectlocker_test?user=projectlocker"
slick.dbs.test.db.url=${?TEST_DB_URL}
slick.dbs.test.db.properties.url="jdbc:postgresql://localhost:5432/projectlocker_test?user=projectlocker&password=projectlocker&connectTimeout=30"
slick.dbs.test.db.properties.url=${?TEST_DB_PROPERTIES_URL}

slick.dbs.test.db.user="projectlocker"
slick.dbs.test.db.password="projectlocker"
slick.dbs.test.db.database="projectlocker_test"
slick.dbs.test.db.connectionTimeout=30s
slick.dbs.test.db.numThreads=10
slick.dbs.test.db.connectionTestQuery="/*ping*/ select 1"
play.evolutions.db.test.autoApply = true
play.evolutions.db.test.autoApplyDowns = true

// can now set DATABASE_URL to a JDBC URI to access database with this
slick.dbs.default.profile="slick.jdbc.PostgresProfile$"
slick.dbs.default.db.dataSourceClass = "slick.jdbc.DatabaseUrlDataSource"
slick.dbs.default.db.driver = "org.postgresql.Driver"
slick.dbs.default.db.url="jdbc:postgresql://localhost:5432/postgres?user=projectlocker"
slick.dbs.default.db.url=${?DEFAULT_DB_URL}
slick.dbs.default.db.properties.url="jdbc:postgresql://localhost:5432/postgres?user=projectlocker&password=projectlocker"
slick.dbs.default.db.properties.url=${?DEFAULT_DB_PROPERTIES_URL}
slick.dbs.default.db.user="projectlocker"
slick.dbs.default.db.password="projectlocker"
slick.dbs.default.db.connectionTimeout=30s
slick.dbs.default.db.database="projectlocker"
slick.dbs.default.db.numThreads=10
slick.dbs.default.db.connectionTestQuery="/*ping*/ select 1"


play.http.parser.maxMemoryBuffer=512K
play.http.parser.maxDiskBuffer=419430400


ldap {
  ldapProtocol = "none"
  ldapUseKeystore = true
  ldapPort = 636
  ldapHost0 = "adhost1.myorg.int"
  ldapHost1 = "adhost2.myorg.int"
  bindDN = "aduser"
  bindPass = "adpassword"
  poolSize = 3
  roleBaseDN = "DC=myorg,DC=com"
  userBaseDN = "DC=myorg,DC=com"
  uidAttribute = "samAccountName"
  memberAttribute = "member"
  roleMemberAttribute = "memberOf"
  roleAttribute = "CN"
  trustStore = "secure/keystore.jks"
  trustStorePass = "BeanstalkToTheStars"
  trustStoreType = "JKS"
  ldapCacheDuration = 600
  acg1 = "acg-name-1"
  admin-groups = ["AG Multimedia Admin"]
}

# Session configuration
play.http.session = {

  # The cookie name
  cookieName = "projectlocker_session"

  # Whether the secure attribute of the cookie should be set to true, i.e. only send over https.
  # we want https in production but might not be able to use it if this is done at the LB
  secure = false

  # The max age to set on the cookie.
  # If null, the cookie expires when the user closes their browser.
  # An important thing to note, this only sets when the browser will discard the cookie.
  maxAge = null

  # Whether the HTTP only attribute of the cookie should be set to true. this prevents the cookie from being accessible
  # to client-side javascript and therefore XSS attacks
  httpOnly = true

  # The value of the SameSite attribute of the cookie. Set to null for no SameSite attribute.
  sameSite = "strict"

  # The domain to set on the session cookie
  # If null, does not set a domain on the session cookie.
  # You should change this to your deployment domain
  domain = null

  # The session path
  # Must start with /.
  path = ${play.http.context}

  jwt {
    # The JWT signature algorithm to use on the session cookie
    # uses 'alg' https://tools.ietf.org/html/rfc7515#section-4.1.1
    signatureAlgorithm = "HS256"

    # The time after which the session is automatically invalidated.
    # Use 'exp' https://tools.ietf.org/html/rfc7519#section-4.1.4
    expiresAfter = ${play.http.session.maxAge}

    # The amount of clock skew to accept between servers when performing date checks
    # If you have NTP or roughtime synchronizing between servers, you can enhance
    # security by tightening this value.
    clockSkew = 1 minutes

    # The claim key under which all user data is stored in the JWT.
    dataClaim = "data"
  }
}

#akka cluster
akka {

  loggers = ["akka.event.slf4j.Slf4jLogger"]
  loglevel = "DEBUG"
  pluto-message-dispatcher {
    type = Dispatcher
    executor = "fork-join-executor"

    fork-join-executor {
      parallelism-min = 2
      parallelism-factor = 2.0
      parallelism-max = 4
    }
    throughput = 1
  }

  management {
    http {
      hostname = "localhost"
      hostname = ${?HOSTNAME}
      bind-hostname = "0.0.0.0"
      port = 8558
      bind-port = 8558
    }
    cluster.bootstrap {
      new-cluster-enabled=on
      contact-point-discovery {
        discovery-method = config #or kubernetes, or akka-dns, etc
        service-name = "projectlocker"
        required-contact-point-nr = 0 // minimum number of nodes to bootstrap the cluster
        required-contact-point-nr = ${?REQUIRED_CONTACT_POINTS}
      }
    }
  }

  //  io.dns.resolver = async-dns
  discovery.config.services {
    projectlocker {
      endpoints = [
        {
          host = "localhost"
          host = ${?HOSTNAME}
          port = 8558
        }
      ]
    }
  }
//  discovery {
//    method = kubernetes-api
//    method = ${?DISCOVERY_METHOD}
//
//    kubernetes-api {
//      pod-namespace = "default" // in which namespace cluster is running
//      pod-namespace = ${?K8S_NAMESPACE}
//      pod-label-selector = "app=akka-simple-cluster" // selector - how to find other cluster nodes
//      pod-label-selector = ${?K8S_SELECTOR}
//      pod-port-name = "management" // name of cluster management port
//      pod-port-name = ${?K8S_MANAGEMENT_PORT}
//    }
//  }

  actor {
    provider = "cluster"

    deployment {
      /message-processor-actor {
        dispatcher = pluto-message-dispatcher
      }
    }

    serializers {
      proto = "akka.remote.serialization.ProtobufSerializer"
      jackson-json = "akka.serialization.jackson.JacksonJsonSerializer"
      jackson-cbor = "akka.serialization.jackson.JacksonCborSerializer"
    }

    serialization-bindings {
      "services.CommissionStatusPropagator$CommissionStatusUpdate": jackson-json
      "services.actors.MessageProcessorActor": jackson-json
      "services.actors.MessageProcessorState": jackson-json
      "services.JacksonSerializable": jackson-json
    }
  }

  remote {
    log-remote-lifecycle-events = off
    artery {
      canonical {
        hostname = "127.0.0.1"
        port = 0
      }
    }
  }

  cluster {
    # keep seed-nodes empty, akka management bootstrap will then initialise the cluster (this is what you probably want)
    seed-nodes = [
      ]


    # auto downing is NOT safe for production deployments.
    # you may want to use it during development, read more about it in the docs.
    #
    # auto-down-unreachable-after = 10s
  }

  persistence {
    journal {
      #NOTE - In testing, this gets overriden in the BuildMyApp trait
      #plugin = "akka.persistence.journal.inmem"
      plugin = "jdbc-journal"
      auto-start-journals = ["jdbc-journal"]
    }
      # NOTE - In testing, this gets overridden in the BuildMyApp trait
    snapshot-store {
      #  plugin = "akka.persistence.snapshot-store.local"
      plugin = "jdbc-snapshot-store"
      auto-start-snapshot-stores = ["jdbc-snapshot-store"]
    }
  }

}

akka-persistence-jdbc {
    shared-databases {
        slick {
            profile = "slick.jdbc.PostgresProfile$"
            db {
                host = "localhost"
                host = ${?POSTGRES_HOST}
                url = "jdbc:postgresql://"${akka-persistence-jdbc.shared-databases.slick.db.host}":5432/"${akka-persistence-jdbc.shared-databases.slick.db.database}"?reWriteBatchedInserts=true"
                user = "postgres"
                user = ${?POSTGRES_USER}
                password = "postgres"
                password = ${?POSTGRES_PASSWORD}
                database = "journal"
                database = ${?JOURNAL_POSTGRES_DB}
                driver = "org.postgresql.Driver"
                numThreads = 5
                maxConnections = 5
                minConnections = 1
            }
        }
    }
}

jdbc-journal {
    use-shared-db = "slick"
}

jdbc-snapshot-store {
    use-shared-db = "slick"
}

# the akka-persistence-query provider in use
jdbc-read-journal {
  use-shared-db = "slick"
}

# Enable metrics extension in akka-cluster-metrics.
//akka.extensions=["akka.cluster.metrics.ClusterMetricsExtension","akka.cluster.pubsub.DistributedPubSub"]

# Sigar native library extract location during tests.
# Note: use per-jvm-instance folder when running multiple jvm on one host.
akka.cluster.metrics.native-library-extract-folder=${user.dir}/target/native


postrun {
  scriptsPath = "postrun/scripts/"
}

pluto {
  server_url = "https://my-server"
  sync_enabled = "no"
  username = "user"
  password = "password"
  sitename = "VX"
  pageSize = 100
  resend_delay = 30 seconds
  persistence-snapshot-interval = 50
}

rabbitmq {
  uri = "amqp://localhost:5672"
}

shared_secret = "rubbish"

external {
  //to allow external sites to access Projectlocker via CORS, put the base URL (without trailing /) into this whitelist
  allowedFrontendDomains = [
  ]
}

deployment-root = ""
auth {
  adminClaim = "field-set-to-true-if-youre-admin"
  tokenSigningCert = """
  PUT YOUR CERT HERE
  """
}
